{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports at the top of the Notebook for ease of use\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer perceptron\n",
    "\n",
    "In this notebook, we'll train a simple neural network to recognize hand-written digits.\n",
    "\n",
    "__1. The dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset contains 70,000 samples, consisting of a 28x28 greyscale image, and a label. The images have been flattened to a feature vector with 784 dimensions. The labels are one-hot encoded in a 10-dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reshape a training image for display purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8a98f7a5f8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYUlKZAhLUiJDWJISGcKSlMgQlqRE/wd0lN3452f75wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8af417fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[2].reshape([28, 28]), cmap='Greys', interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. The model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_1 = tf.Variable(tf.truncated_normal(shape=[784, 64], stddev=0.1))\n",
    "b_1 = tf.Variable(tf.constant(0.0, shape=[64]))\n",
    "\n",
    "W_2 = tf.Variable(tf.truncated_normal(shape=[64, 10], stddev=0.1))\n",
    "b_2 = tf.Variable(tf.constant(0.0, shape=[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "h_1 = tf.nn.relu(tf.matmul(x, W_1) + b_1)\n",
    "y = tf.matmul(h_1, W_2) + b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0726\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The untrained model achieves an accuracy a little over 10%, which is slightly better than randomly assigning a label to each training image.\n",
    "\n",
    "__3. Defining the loss and picking an optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Performing gradient descent__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.968\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
